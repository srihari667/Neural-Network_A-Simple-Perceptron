# ðŸ§  Neural Network - A Simple Perceptron  

This repository contains solutions and implementations for the **Neural Network (A Simple Perceptron)** assignment.  
The assignment explores fundamental deep learning concepts, including perceptrons, activation functions, optimizers, and neural network architectures.  

---

## ðŸ“˜ Assignment Overview

| **Question** | **Topic** | **Tools/Concepts Used** |
|---------------|------------|--------------------------|
| Q1 | Introduction to Deep Learning | Theory |
| Q2 | Perceptron Architecture and Limitations | Theory |
| Q3 | Activation Functions (Sigmoid, ReLU, Tanh) | Theory |
| Q4 | Loss Function vs Cost Function | Theory |
| Q5 | Role of Optimizers (GD, Adam, RMSprop) | Theory |
| Q6 | Single-layer Perceptron (AND Gate) | NumPy |
| Q7 | Visualization of Activation Functions | Matplotlib |
| Q8 | Multilayer Neural Network (MNIST Dataset) | TensorFlow / Keras |
| Q9 | Training Visualization (Fashion MNIST) | Matplotlib |
| Q10 | Real-time Deep Learning Workflow (Fraud Detection) | Deep Learning Design & Implementation |

---

## ðŸ§© Technologies Used

- **Python 3.x**
- **NumPy**
- **Matplotlib**
- **TensorFlow / Keras**
- **Google Colab / Jupyter Notebook**

---

## ðŸš€ Implementation Details

### Q6 â€“ Single-Layer Perceptron (AND Gate)
- Implemented from scratch using **NumPy**.
- Demonstrates how a perceptron can learn logical operations.
- Shows weight updates over training iterations.

### Q7 â€“ Activation Function Visualization
- Implemented **Sigmoid**, **ReLU**, and **Tanh** functions.
- Used **Matplotlib** to plot activation functions and understand their behavior.

### Q8 â€“ Simple Multilayer Neural Network (MNIST)
- Built using **Keras Sequential API**.
- Contains multiple dense layers.
- Evaluated model accuracy and printed training accuracy.

### Q9 â€“ Training Curves on Fashion MNIST
- Visualized **loss** and **accuracy** using Matplotlib.
- Interpreted overfitting and underfitting based on the curves.

### Q10 â€“ Fraud Detection Workflow
- Designed a **real-time fraud detection pipeline**.
- Used **imbalanced data handling**, **Adam optimizer**, and **BCEWithLogitsLoss**.
- Included strategies like dropout and early stopping to prevent overfitting.

---

